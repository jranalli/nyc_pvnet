{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Image Preprocessing Workflow\n",
    "This notebook demonstrates the preprocessing workflow used to prepare images from the [New York GIS Clearinghouse orthoimagery dataset](https://gis.ny.gov/gateway/mg/index.html) for semantic segmentation analysis.\n",
    "\n",
    "Begin by importing the libraries we need"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import utils"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract Images\n",
    "We started our labelling process with the High Resolution 2018 Imagery for Queens available from the [Download Page](https://gis.ny.gov/gateway/mg/2018/new_york_city/).\n",
    "\n",
    "The images have a resolution of 0.5 ft per pixel and are in four bands (RGB + Infrared). Images are formatted as JPEG2000, which requires conversion for use by [labelme](https://github.com/wkentaro/labelme) and the subsequent parts of the workflow. We extract the images as 3 channel by default, because the 4th channel is interpreted as transparency by default."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB Output path not empty. Skipping entire operation.\n"
     ]
    }
   ],
   "source": [
    "zipfn = \"c:\\\\nycdata\\\\boro_queens_sp18.zip\"\n",
    "png_dir = \"c:\\\\nycdata\\\\boro_queens_sp18_png\"\n",
    "ir_dir = \"c:\\\\nycdata\\\\boro_queens_sp18_png_ir\"\n",
    "utils.zip_to_png(zipfn, png_dir, ir_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Label Images\n",
    "At this point, we conducted image labeling. We used [labelme](https://github.com/wkentaro/labelme) and created polygons for each image. The polygons were given three different labels:\n",
    "- `pv` for obvious pv installations.\n",
    "- `notpv` for empty rings within a larger polygon.\n",
    "- `maybe` for uncertain spots that required further review.\n",
    "\n",
    "\n",
    "<img src=\"../example_label.png\" alt=\"Rooftop\" width=400>\n",
    "\n",
    "The labels were saved into JSON files co-located with the images, and with identical filenames. Labelme defaults to saving a copy of the image within the JSON file, and it's easy to forget to turn that off. So there is a helper to strip out the image data from a whole directory of JSON files. Additionally, labelme does not create JSON for images with no labelled sections. Since we might still care about these images, we have a tool to generate blank JSON files for images that do not already have a JSON label. Finally, we provide a tool to convert the JSON files into the binary image masks. Generating the masks works best when we provide a dictionary correlating each label name to a value for the mask."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n",
      "Mask file exists: skipping.\n"
     ]
    }
   ],
   "source": [
    "png_dir = \"c:\\\\nycdata\\\\sample_subset\\\\raw\"  # while labelling is still ongoing, we will override the png directory to a manually copied subset\n",
    "mask_dir = \"c:\\\\nycdata\\\\sample_subset\\\\masks\"\n",
    "# Clear all json of imagedata\n",
    "for f in utils.fileio.files_of_type(png_dir, '*.json'):\n",
    "    utils.clear_imagedata(f)\n",
    "\n",
    "# Generate the blank json files\n",
    "utils.generate_blank_json_dir(png_dir)\n",
    "\n",
    "label_vals = {\"_background_\": 0, \"maybe\": 0, \"notpv\": 0, \"pv\": 255}\n",
    "for f in utils.fileio.files_of_type(png_dir, '*.json'):\n",
    "    utils.json_to_binary(f, mask_dir, label_vals)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting Images into Tiles\n",
    "The images that come right from the dataset are 5000 x 5000 pixels. This is much too large for us to work with in the neural network processing. So we want to split both the images and the masks into tiles and send to the same directories."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "png_tile_dir = \"c:\\\\nycdata\\\\sample_subset\\\\final\\\\data\"\n",
    "mask_tile_dir = \"c:\\\\nycdata\\\\sample_subset\\\\final\\\\masks\"\n",
    "\n",
    "tile_size = 625\n",
    "\n",
    "# Operate if the directories are empty\n",
    "if utils.fileio.is_dir_empty(png_tile_dir):\n",
    "    for f in utils.fileio.files_of_type(png_dir, '*.png'):\n",
    "        utils.slice_image(f, tile_size, tile_size, png_tile_dir)\n",
    "if utils.fileio.is_dir_empty(mask_tile_dir):\n",
    "    for f in utils.fileio.files_of_type(mask_dir, '*.png'):\n",
    "        utils.slice_image(f, tile_size, tile_size, mask_tile_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Delete Blank Tiles\n",
    "Because we're slicing up images, there's a possibility that we will end up with a large number of blanks. Drop those from the list of files. The opportunity exists here to set the percentage of blanks that should make up the entire dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "utils.delete_blank_tiles(png_tile_dir, mask_tile_dir, maxfrac=0, seed=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Labels in Dataset: 345\n"
     ]
    }
   ],
   "source": [
    "# Print info about the remaining dataset\n",
    "import glob, os\n",
    "print(f\"Total Number of Labels in Dataset: {len(glob.glob(os.path.join(mask_tile_dir,'*.png')))}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
